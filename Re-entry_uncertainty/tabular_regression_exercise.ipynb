{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tabular_regression_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiyMMUUY2G1j",
        "colab_type": "text"
      },
      "source": [
        "# Re-entry estimation exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auGoHfyOapE6",
        "colab_type": "text"
      },
      "source": [
        "This exercise follows the tabular regression model tutorial, but applies it to the problem of predicting values of the re-entry trajectory and ground impact location, based on the uncertanties on initial conditions, object properties and atmospheric characteristics (See Table 1 of the paper attached to the project preview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYutgbte9yA-",
        "colab_type": "text"
      },
      "source": [
        "The outputs of the regression model will be:\n",
        "1. Latitude\n",
        "2. Longitude\n",
        "\n",
        "Since there are more than one output in the regression model, you can either create a single learner that outputs the two variables, or create two different learners, one to predict each of the outputs. In case you go for the first approach, itâ€™s important to scale your dependent variables before the prediction, otherwise the largest one might dominate everything and you end up optimizing your NN for only one of them. Here are two possible scaling tabular processors (instances of the fastai's `TabularProc` class) that you can introduce when creating the dataloader. You can also do this transformations manually in the input dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM7FKJGxALwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NormalizeDep(TabularProc):\n",
        "    \"Normalize the dependent variables of a TabularPandas object\"\n",
        "    order = 3\n",
        "    def setups(self, dsets): self.y_means,self.y_stds = dsets.ys.mean(),dsets.ys.std(ddof=0)+1e-7\n",
        "    def encodes(self, to): to.ys = (to.ys-self.y_means) / self.y_stds\n",
        "    def decodes(self, to): to.ys = (to.ys*self.y_stds ) + self.y_means"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NS00VqsAbf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogDep(TabularProc):\n",
        "    \"Log-transform the dependent variables of a TabularPandas object. If \\\n",
        "    there are negative values in any of the variables, a translation is applied \\\n",
        "    first using the minimum value of that variable plus 1\"\n",
        "    order = 3\n",
        "    def setups(self, dsets): self.y_log_translation = [abs(x)+1 if x<=0 else 0 for x in list(dsets.ys.min())]\n",
        "    def encodes(self, to): to.ys = np.log(to.ys + self.y_log_translation)\n",
        "    def decodes(self, to): to.ys = np.exp(to.ys) -self.y_log_translation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkRIuybODFlz",
        "colab_type": "text"
      },
      "source": [
        "More specifically, the tasks you are expected to do in this exercise are:\n",
        "\n",
        "1. Create a regression model based on the data that you've previously generated from the black-box propagation model. You should have at least around 200-300 items to create a proper model.\n",
        "\n",
        "2. Test that model with a big input test set (around 1e6 points), generated from sampling the random input variables.\n",
        "\n",
        "3. Perform an analysis of the most important features in the regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXPA8RRf_9rJ",
        "colab_type": "text"
      },
      "source": [
        "Remember to use the LTW-I Slack workspace to ask questions and request mentors to your Zoom room. You can also visit the [fastai2 documentation website](https://dev.fast.ai/) for technical troubleshooting if you use fastai2 as ML library. If you are already familiar with any other ML library for training tabular regression models (NNs, tree-based models, SVMs...), you can perfectly use that instead of the one showed in the tutorial, as long as you fulfill the tasks mentioned above."
      ]
    }
  ]
}